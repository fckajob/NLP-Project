{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 29.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0\n",
      "{'textcat': 0.1600000113248825}\n",
      "Starting iteration 1\n",
      "{'textcat': 0.15161681175231934}\n",
      "Starting iteration 2\n",
      "{'textcat': 0.1377629041671753}\n",
      "Starting iteration 3\n",
      "{'textcat': 0.11752791702747345}\n",
      "Starting iteration 4\n",
      "{'textcat': 0.09192810952663422}\n",
      "{'1 Star': 0.156964510679245, '2 Star': 0.156964510679245, '3 Star': 0.156964510679245, '4 Star': 0.156964510679245, '5 Star': 0.37214195728302}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.pipeline.textcat import DEFAULT_SINGLE_TEXTCAT_MODEL\n",
    "from spacy.util import minibatch\n",
    "from tqdm import tqdm # loading bar\n",
    "from spacy.training.example import Example\n",
    "import random\n",
    "\n",
    "#spacy.prefer_gpu()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "config = {\n",
    "   \"threshold\": 0.5,\n",
    "   \"model\": DEFAULT_SINGLE_TEXTCAT_MODEL,\n",
    "}\n",
    "\n",
    "\n",
    "# Create Text categorizer instance\n",
    "#textcat = nlp.add_pipe(\"textcat\",config=config)\n",
    "textcat = nlp.add_pipe(\"textcat\")\n",
    "\n",
    "#Disable all other pipes except Text Categorizer\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
    "nlp.disable_pipes(*other_pipes)\n",
    "\n",
    "# Add our desired labels for the Text Categorizer \n",
    "textcat.add_label(\"1 Star\")\n",
    "textcat.add_label(\"2 Star\")\n",
    "textcat.add_label(\"3 Star\")\n",
    "textcat.add_label(\"4 Star\")\n",
    "textcat.add_label(\"5 Star\")\n",
    "\n",
    "\n",
    "    \n",
    "exampleText = \"i used to beats headphones but after their partnership with monster cables ended, the quality of their headphones went down hill. i was replacing my beats with new ones every 9-12 months since the headphones keep blowing out. these v-moda headphones are great, never had any issue on the construction and durability of these headphones. the sound quality is top notch and provides a deeper bass sound than beats and bose in-ear headphones. bit on the pricey side, but worth the purchase if you're an avid listener.\"\n",
    "\n",
    "annot = {\n",
    "    \"cats\":{\n",
    "        \"5 Star\" : True,\n",
    "        \"4 Star\" : False,\n",
    "        \"3 Star\" : False,\n",
    "        \"2 Star\" : False,\n",
    "        \"1 Star\" : False,\n",
    "        }\n",
    "    }\n",
    "TRAIN_DATA = list()\n",
    "\n",
    "for i in range(1):\n",
    "    nlp.make_doc(exampleText)\n",
    "    exampleTuple = (exampleText,annot)\n",
    "    TRAIN_DATA.append(exampleTuple)\n",
    "\n",
    "exampleList = list()\n",
    "for text, annotations in TRAIN_DATA:\n",
    "    doc = nlp.make_doc(text)\n",
    "    example = Example.from_dict(doc, annotations)\n",
    "    exampleList.append(example)\n",
    "\n",
    "textcat.initialize(lambda: exampleList, nlp=nlp)\n",
    "\n",
    "#print(train_data)\n",
    "\n",
    "#Training\n",
    "optimizer = nlp.resume_training()\n",
    "for itn in tqdm(range(5)):\n",
    "    print(\"Starting iteration \" + str(itn))\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    #create batches of training data\n",
    "    batches = minibatch(TRAIN_DATA, size=50)\n",
    "    losses = {}\n",
    "    #Implement batching\n",
    "    for batch in batches:\n",
    "        exampleLst = []\n",
    "        for text, annotations in batch:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "            exampleLst.append(example)\n",
    "        losses = textcat.update(exampleLst, sgd=optimizer)\n",
    "        print(losses)\n",
    "\n",
    "doc2 = nlp(\"Great Energy Level VI tr 4343avel charger! Very compact and fast charging. It is the most convenient product I never seen before ! I like it. I am very happy with this seller . Order packed very well and ship fast .Great energy level VI slimmest travel charger . Courteous service !\")\n",
    "print(doc2.cats)\n",
    "\n",
    "\n",
    "##print('Iterations',iterations,'ExecutionTime',time.time()-start)\n",
    "\n",
    "\n",
    "\n",
    "def createExampleObject(Review: str, stars: int):\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 9076: expected 15 fields, saw 22\\nSkipping line 19256: expected 15 fields, saw 22\\nSkipping line 24313: expected 15 fields, saw 22\\nSkipping line 47211: expected 15 fields, saw 22\\nSkipping line 54295: expected 15 fields, saw 22\\nSkipping line 56641: expected 15 fields, saw 22\\nSkipping line 63067: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 93796: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 132806: expected 15 fields, saw 22\\nSkipping line 164631: expected 15 fields, saw 22\\nSkipping line 167019: expected 15 fields, saw 22\\nSkipping line 167212: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 198103: expected 15 fields, saw 22\\nSkipping line 199191: expected 15 fields, saw 22\\nSkipping line 202841: expected 15 fields, saw 22\\nSkipping line 218228: expected 15 fields, saw 22\\nSkipping line 235900: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 277761: expected 15 fields, saw 22\\nSkipping line 304582: expected 15 fields, saw 22\\nSkipping line 312029: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 343692: expected 15 fields, saw 22\\nSkipping line 352291: expected 15 fields, saw 22\\nSkipping line 363414: expected 15 fields, saw 22\\nSkipping line 378087: expected 15 fields, saw 22\\nSkipping line 378720: expected 15 fields, saw 22\\nSkipping line 378760: expected 15 fields, saw 22\\nSkipping line 379336: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 402682: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 466560: expected 15 fields, saw 22\\nSkipping line 486823: expected 15 fields, saw 22\\nSkipping line 489036: expected 15 fields, saw 22\\nSkipping line 496148: expected 15 fields, saw 22\\nSkipping line 522330: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 552961: expected 15 fields, saw 22\\nSkipping line 577388: expected 15 fields, saw 22\\nSkipping line 582182: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 590653: expected 15 fields, saw 22\\nSkipping line 608846: expected 15 fields, saw 22\\nSkipping line 615442: expected 15 fields, saw 22\\nSkipping line 645607: expected 15 fields, saw 22\\nSkipping line 654323: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 714935: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 749608: expected 15 fields, saw 22\\nSkipping line 753868: expected 15 fields, saw 22\\nSkipping line 762504: expected 15 fields, saw 22\\nSkipping line 771706: expected 15 fields, saw 22\\nSkipping line 773376: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 792407: expected 15 fields, saw 22\\nSkipping line 793933: expected 15 fields, saw 22\\nSkipping line 813269: expected 15 fields, saw 22\\nSkipping line 835491: expected 15 fields, saw 22\\nSkipping line 841176: expected 15 fields, saw 22\\nSkipping line 844604: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 857952: expected 15 fields, saw 22\\nSkipping line 859568: expected 15 fields, saw 22\\nSkipping line 860789: expected 15 fields, saw 22\\nSkipping line 863093: expected 15 fields, saw 22\\nSkipping line 881608: expected 15 fields, saw 22\\nSkipping line 891157: expected 15 fields, saw 22\\nSkipping line 893799: expected 15 fields, saw 22\\nSkipping line 906438: expected 15 fields, saw 22\\nSkipping line 914856: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 940736: expected 15 fields, saw 22\\nSkipping line 965818: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 993840: expected 15 fields, saw 22\\nSkipping line 1019036: expected 15 fields, saw 22\\nSkipping line 1019205: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1058122: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1144887: expected 15 fields, saw 22\\nSkipping line 1147255: expected 15 fields, saw 22\\nSkipping line 1164497: expected 15 fields, saw 22\\nSkipping line 1166930: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1218319: expected 15 fields, saw 22\\nSkipping line 1232868: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1307335: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1621422: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1857720: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1935753: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1988449: expected 15 fields, saw 22\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672\n",
      "1509930    i used to beats headphones but after their par \n",
      "1036164    it is not difficult to set up the alarm and eve \n",
      "240069                           they work great no issuess\n",
      "2235881    easy mount perfect mount and easy to install  \n",
      "1503924    worked great until it popped after 9 months p \n",
      "                                  \n",
      "822215                        my grand daughter loves these \n",
      "2227643    bought them for a hard to buy older boy who ab \n",
      "2713881    these headphones are great but only for mp3 p \n",
      "1055292    the sound is great and they are super simple t \n",
      "29829      nice and compact comfortable to wear for long \n",
      "Name: review_body Length: 2472696 dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore') # Hides warning\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Data cleaning\n",
    "\n",
    "missing_value = [\"N/a\", \"na\", np.nan, np.NAN, np.NaN, \"null\"]\n",
    "df = pd.read_table('amazon_reviews_us_Electronics_v1_00.tsv', error_bad_lines=False, na_values=missing_value)\n",
    "\n",
    "df = df.dropna()\n",
    "data = df.copy()\n",
    "review_id = len(data[\"review_id\"].unique())\n",
    "#print(\"review_id: \" + str(review_id))\n",
    "\n",
    "\n",
    "# Visualizing the distributions of numerical variables:\n",
    "\n",
    "#data.hist(bins=50, figsize=(20,15))\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Train/Test Split\n",
    "training_data, testing_data = train_test_split(data, test_size=0.2, random_state=25)\n",
    "\n",
    "#data.info()\n",
    "\n",
    "# Normalization : 1- converting all the characters to lowercase\n",
    "\n",
    "training_data['review_body'] = training_data['review_body'].str.lower()\n",
    "training_data['review_headline'] = training_data['review_headline'].str.lower()\n",
    "\n",
    "\n",
    "\n",
    "# Normalization : 2- converting all whitespace and punctuation into a single space to get rid of any inconsistencies.\n",
    "review_body = re.sub(' +', ' ', str(training_data['review_body']))\n",
    "review_headline = re.sub(' +', ' ', str(training_data['review_headline']))\n",
    "\n",
    "\n",
    "\n",
    "review_body = re.sub(r\"\"\"\n",
    "               [,.;@#?!&$]+  # Accept one or more copies of punctuation\n",
    "               \\ *           # plus zero or more copies of a space,\n",
    "               \"\"\",\n",
    "               \" \",          # and replace it with a single space\n",
    "               str(training_data['review_body']), flags=re.VERBOSE)\n",
    "review_headline = re.sub(r\"\"\"\n",
    "               [,.;@#?!&$]+  # Accept one or more copies of punctuation\n",
    "               \\ *           # plus zero or more copies of a space,\n",
    "               \"\"\",\n",
    "               \" \",          # and replace it with a single space\n",
    "               str(training_data['review_headline']), flags=re.VERBOSE)\n",
    "\n",
    "\n",
    "# Noise Removal: Removing HTML Tags (using BeautifulSoup’s)\n",
    "\n",
    "review_body = BeautifulSoup(review_body, \"lxml\").text\n",
    "\n",
    "\n",
    "\n",
    "# Noise Removal: Expanding Contractions\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    return phrase\n",
    "\n",
    "review_body = decontracted(review_body)\n",
    "\n",
    "\n",
    "print(len(review_body))\n",
    "print(review_body)\n",
    "\n",
    "\n",
    "# TODO: Either save cleaned dataset as new file or warp in function and return to model.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
